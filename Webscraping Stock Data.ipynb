{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h1>Extracting Stock Data Using a Web Scraping</h1>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#!pip install pandas==1.3.3\n","#!pip install requests==2.26.0\n","!mamba install bs4==4.10.0 -y\n","!mamba install html5lib==1.1 -y\n","!pip install lxml==4.6.4\n","#!pip install plotly==5.3.1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup"]},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"notes"}},"source":["## Using Webscraping to Extract Stock Data Example\n"]},{"cell_type":"markdown","metadata":{},"source":[" <https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html\"\n","\n","data  = requests.get(url).text"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["soup = BeautifulSoup(data, 'html5lib')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["netflix_data = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n","\n","# First we isolate the body of the table which contains all the information\n","# Then we loop through each row and find all the column values for each row\n","for row in soup.find(\"tbody\").find_all('tr'):\n","    col = row.find_all(\"td\")\n","    date = col[0].text\n","    Open = col[1].text\n","    high = col[2].text\n","    low = col[3].text\n","    close = col[4].text\n","    adj_close = col[5].text\n","    volume = col[6].text\n","    \n","    # Finally we append the data of each row to the table\n","    netflix_data = netflix_data.append({\"Date\":date, \"Open\":Open, \"High\":high, \"Low\":low, \"Close\":close, \"Adj Close\":adj_close, \"Volume\":volume}, ignore_index=True)    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["netflix_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["read_html_pandas_data = pd.read_html(url)"]},{"cell_type":"markdown","metadata":{},"source":["Or we can convert the BeautifulSoup object to a string\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["read_html_pandas_data = pd.read_html(str(soup))"]},{"cell_type":"markdown","metadata":{},"source":["Beacause there is only one table on the page, we just take the first table in the list returned\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["netflix_dataframe = read_html_pandas_data[0]\n","\n","netflix_dataframe.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Using Webscraping to Extract Stock Data Exercise\n"]},{"cell_type":"markdown","metadata":{},"source":["Use the `requests` library to download the webpage <https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/amazon_data_webpage.html>. Save the text of the response as a variable named `html_data`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["url = \"https://finance.yahoo.com/quote/AMZN/history?period1=1451606400&period2=1612137600&interval=1mo&filter=history&frequency=1mo&includeAdjustedClose=true\"\n","html_data = requests.get(url).text"]},{"cell_type":"markdown","metadata":{},"source":["Parse the html data using `beautiful_soup`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["soup = BeautifulSoup(html_data,\"html5lib\")"]},{"cell_type":"markdown","metadata":{},"source":["<b>Question 1</b> What is the content of the title attribute:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["soup.title"]},{"cell_type":"markdown","metadata":{},"source":["Using beautiful soup extract the table with historical share prices and store it into a dataframe named `amazon_data`. The dataframe should have columns Date, Open, High, Low, Close, Adj Close, and Volume. Fill in each variable with the correct data from the list `col`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["amazon_data = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n","\n","for row in soup.find(\"tbody\").find_all(\"tr\"):\n","    col = row.find_all(\"td\")\n","    date = #ADD_CODE\n","    Open = #ADD_CODE\n","    high = #ADD_CODE\n","    low = #ADD_CODE\n","    close = #ADD_CODE\n","    adj_close = #ADD_CODE\n","    volume = #ADD_CODE\n","    \n","    amazon_data = amazon_data.append({\"Date\":date, \"Open\":Open, \"High\":high, \"Low\":low, \"Close\":close, \"Adj Close\":adj_close, \"Volume\":volume}, ignore_index=True)"]},{"cell_type":"markdown","metadata":{},"source":["Print out the first five rows of the `amazon_data` dataframe you created.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["amazon_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["<b>Question 2</b> What is the name of the columns of the dataframe\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["amazon_data.columns"]},{"cell_type":"markdown","metadata":{},"source":["<b>Question 3</b> What is the `Open` of the last row of the amazon_data dataframe?\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","amazon_data.loc[amazon_data[\"Date\"]==\"Jun 01, 2019\"]"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"87bbfac4756757c17e0820b33808dfedb7be4f1ad41308c76e863d0a46f80df5"}}},"nbformat":4,"nbformat_minor":4}
